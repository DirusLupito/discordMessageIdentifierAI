{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load data/Noah-Noah-Discord-Conversation.csv\n",
    "\n",
    "# In this dataset, the message author is given in column 4 (the fifth column),\n",
    "# and the message content is given in column 15 (the sixteenth column).\n",
    "# The dataset contains all the direct messages between Noah (diruslupito in the data) and Noah (gamemaster618) on Discord before February 29, 2024.\n",
    "data = pd.read_csv('data/Alex-Noah-Discord-Conversation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author.username</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diruslupito</td>\n",
       "      <td>ok he said yes, ill make a gc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diruslupito</td>\n",
       "      <td>I'll ask my roommate if you can join our 422 g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gamemaster618</td>\n",
       "      <td>Yeah this class is gonna suck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diruslupito</td>\n",
       "      <td>Might as well do practice problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gamemaster618</td>\n",
       "      <td>Up front near the middle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author.username                                            content\n",
       "0     diruslupito                      ok he said yes, ill make a gc\n",
       "1     diruslupito  I'll ask my roommate if you can join our 422 g...\n",
       "2   gamemaster618                      Yeah this class is gonna suck\n",
       "3     diruslupito                 Might as well do practice problems\n",
       "4   gamemaster618                           Up front near the middle"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploratory data analysis\n",
    "\n",
    "# Print the dataframe's head (most recent 5 by default) messages, \n",
    "# with author as the leftmost column and message content as the rightmost column\n",
    "display(data.iloc[:, [4, 15]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author.username\n",
       "diruslupito      326\n",
       "gamemaster618    199\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the total number of messages sent by each person\n",
    "display(data.iloc[:, 4].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok he said yes, ill make a gc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in that message:  8\n"
     ]
    }
   ],
   "source": [
    "# Count the number of words sent in the most recent message\n",
    "most_recent_message = data.iloc[0, 15]\n",
    "display(most_recent_message)\n",
    "print('Words in that message: ', len(most_recent_message.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text messages by Alex: 303\n",
      "Number of text messages by Noah: 197\n",
      "Number of text messages: 500\n",
      "Total number of messages: 525\n",
      "Number of words written by Alex: 2420\n",
      "Number of words written by Noah: 1750\n",
      "Total number of words written: 4170\n",
      "Average per message by Alex: 7.986798679867987\n",
      "Average per message by Noah: 8.883248730964468\n",
      "Average per message: 8.34\n"
     ]
    }
   ],
   "source": [
    "# Count the number of words sent across all messages, \n",
    "# separated by author\n",
    "sumAlex = 0\n",
    "sumNoah = 0\n",
    "numTextMessagesByAlex = 0\n",
    "numTextMessagesByNoah = 0\n",
    "for i in range(len(data)):\n",
    "    # Skip NaN values\n",
    "    if pd.isnull(data.iloc[i, 15]):\n",
    "        continue\n",
    "    if data.iloc[i, 4] == 'diruslupito':\n",
    "        numTextMessagesByAlex += 1\n",
    "        sumAlex += len(data.iloc[i, 15].split())\n",
    "    else:\n",
    "        numTextMessagesByNoah += 1\n",
    "        sumNoah += len(data.iloc[i, 15].split())\n",
    "print('Number of text messages by Alex:', numTextMessagesByAlex)\n",
    "print('Number of text messages by Noah:', numTextMessagesByNoah)\n",
    "print('Number of text messages:', numTextMessagesByAlex + numTextMessagesByNoah)\n",
    "print('Total number of messages:', len(data))\n",
    "print('Number of words written by Alex:', sumAlex)\n",
    "print('Number of words written by Noah:', sumNoah)\n",
    "print('Total number of words written:', sumAlex + sumNoah)\n",
    "print('Average per message by Alex:', sumAlex / numTextMessagesByAlex)\n",
    "print('Average per message by Noah:', sumNoah / numTextMessagesByNoah)\n",
    "print('Average per message:', (sumAlex + sumNoah) / (numTextMessagesByAlex + numTextMessagesByNoah))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': 1, 'he': 1, 'said': 1, 'yes,': 1, 'ill': 1, 'make': 1, 'a': 1, 'gc': 1}\n"
     ]
    }
   ],
   "source": [
    "# Look at the most recent message, and add all of its words to a map which maps words to their frequency\n",
    "wordFrequency = {}\n",
    "for word in most_recent_message.split():\n",
    "    if word in wordFrequency:\n",
    "        wordFrequency[word] += 1\n",
    "    else:\n",
    "        wordFrequency[word] = 1\n",
    "print(wordFrequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words used by Alex: 893\n",
      "Number of distinct words used by Noah: 776\n",
      "Number of distinct words used by both: 1369\n",
      "Alex's most used 15 words are: i(86 uses), the(72 uses), to(56 uses), it(55 uses), a(50 uses), in(31 uses), this(30 uses), for(29 uses), and(29 uses), of(26 uses), is(26 uses), like(24 uses), my(22 uses), on(20 uses), not(18 uses).\n",
      "Noah's most used 15 words are: I(64 uses), the(56 uses), to(45 uses), it(44 uses), is(32 uses), a(31 uses), that(27 uses), was(23 uses), Yeah(19 uses), you(19 uses), in(18 uses), and(18 uses), on(17 uses), of(15 uses), for(15 uses).\n",
      "The most used 15 words by both are: the(128 uses), to(101 uses), it(99 uses), i(86 uses), I(82 uses), a(81 uses), is(58 uses), in(49 uses), and(47 uses), for(44 uses), this(42 uses), of(41 uses), that(40 uses), on(37 uses), was(36 uses).\n"
     ]
    }
   ],
   "source": [
    "# Look at all messages, and add all of their words to a map which maps words to their frequency,\n",
    "# separated by author\n",
    "\n",
    "wordFrequencyAlex = {}\n",
    "wordFrequencyNoah = {}\n",
    "wordFrequencyBoth = {}\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # Skip NaN values\n",
    "    if pd.isnull(data.iloc[i, 15]):\n",
    "        continue\n",
    "    for word in data.iloc[i, 15].split():\n",
    "        if data.iloc[i, 4] == 'diruslupito':\n",
    "            if word in wordFrequencyAlex:\n",
    "                wordFrequencyAlex[word] += 1\n",
    "            else:\n",
    "                wordFrequencyAlex[word] = 1\n",
    "        else:\n",
    "            if word in wordFrequencyNoah:\n",
    "                wordFrequencyNoah[word] += 1\n",
    "            else:\n",
    "                wordFrequencyNoah[word] = 1\n",
    "        if word in wordFrequencyBoth:\n",
    "            wordFrequencyBoth[word] += 1\n",
    "        else:\n",
    "            wordFrequencyBoth[word] = 1\n",
    "\n",
    "print('Number of distinct words used by Alex:', len(wordFrequencyAlex))\n",
    "print('Number of distinct words used by Noah:', len(wordFrequencyNoah))\n",
    "print('Number of distinct words used by both:', len(wordFrequencyBoth))\n",
    "\n",
    "# Add the words to a list, sorted in descending order of frequency\n",
    "wordListAlex = sorted(wordFrequencyAlex, key=wordFrequencyAlex.get, reverse=True)\n",
    "wordListNoah = sorted(wordFrequencyNoah, key=wordFrequencyNoah.get, reverse=True)\n",
    "wordListBoth = sorted(wordFrequencyBoth, key=wordFrequencyBoth.get, reverse=True)\n",
    "\n",
    "\n",
    "# Print the most used words by each person, and the most used words by both\n",
    "numWordsToPrint = 15\n",
    "\n",
    "# Alex's most used words\n",
    "printstr = 'Alex\\'s most used ' + str(numWordsToPrint) + ' words are: '\n",
    "for i in range(numWordsToPrint):\n",
    "    printstr += wordListAlex[i]\n",
    "    printstr += '(' + str(wordFrequencyAlex[wordListAlex[i]]) + ' uses)'\n",
    "    printstr += ', '\n",
    "printstr = printstr[:-2]\n",
    "printstr += '.'\n",
    "print(printstr)\n",
    "\n",
    "# Noah's most used words\n",
    "printstr = 'Noah\\'s most used ' + str(numWordsToPrint) + ' words are: '\n",
    "for i in range(numWordsToPrint):\n",
    "    printstr += wordListNoah[i]\n",
    "    printstr += '(' + str(wordFrequencyNoah[wordListNoah[i]]) + ' uses)'\n",
    "    printstr += ', '\n",
    "printstr = printstr[:-2]\n",
    "printstr += '.'\n",
    "print(printstr)\n",
    "\n",
    "# Most used words by both\n",
    "printstr = 'The most used ' + str(numWordsToPrint) + ' words by both are: '\n",
    "for i in range(numWordsToPrint):\n",
    "    printstr += wordListBoth[i]\n",
    "    printstr += '(' + str(wordFrequencyBoth[wordListBoth[i]]) + ' uses)'\n",
    "    printstr += ', '\n",
    "printstr = printstr[:-2]\n",
    "printstr += '.'\n",
    "print(printstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok he said yes, ill make a gc',\n",
       " \"I'll ask my roommate if you can join our 422 group\",\n",
       " 'Yeah this class is gonna suck',\n",
       " 'Might as well do practice problems',\n",
       " 'Up front near the middle',\n",
       " 'Better than snoozing through 3 hours of lecture',\n",
       " \"Didn't realize you were in this class too\",\n",
       " 'That sounds riviting lmao',\n",
       " 'Meth 520 linear algebruh',\n",
       " 'Doing meth',\n",
       " 'Question is that you sitting in the corner in 422 rn?',\n",
       " 'Maybe it just means taking both is an excess of units but who knows',\n",
       " 'though, idk what that \"Course provides excess units, Approved Exception\" line means since MA 405 is the same number of credits as 305',\n",
       " \"well wouldn't you look at that, it worked\",\n",
       " 'So true',\n",
       " 'cant wait for this to somehow result in a colossal fuckup in their system that crashes everything and i get 1000 F grades',\n",
       " 'Was hidden in a subfolder',\n",
       " 'i think so anyways',\n",
       " 'This what you need?',\n",
       " 'post it',\n",
       " 'Found it',\n",
       " 'nothing to do with substitutions as far as i can find',\n",
       " 'it just links to the advising webpage',\n",
       " 'nah, its online',\n",
       " 'It would be funny if they let the cite go offline',\n",
       " 'Wait what? Let me check thats weird',\n",
       " 'i need to use the form to get MA 405 substituted for 305',\n",
       " 'but this link takes me to a different page',\n",
       " 'i need the one for this',\n",
       " 'did they thanos snap the CSC forms page out of existence',\n",
       " 'Oh I see\\nYeah thats rough',\n",
       " 'like when i made a dfa that accepted a single string like \"blah\" when they wanted it to only accept \"b\", \"l\", \"a\" or \"h\" (something like that, i forgot exactly',\n",
       " 'there were multiple where i did silly things',\n",
       " 'not just 1 question',\n",
       " 'What was the question?',\n",
       " 'if i had read the words they wrote on the first test, i may yet have made an A',\n",
       " 'Pleasent surprise',\n",
       " 'A+ here',\n",
       " 'looks like I did not have to wait until monday',\n",
       " 'got an A-',\n",
       " 'oh well',\n",
       " 'Since she waited so long not till Monday',\n",
       " 'wonder when the grades will be visible on mypack',\n",
       " '312/320 here\\nI feel like I should be fine but claculating the HW grade is such a pain I dont want to bother yknow',\n",
       " 'hopefully gets me an A for the overall grade',\n",
       " 'i got 299/320',\n",
       " \"Exam score is in for my section on gradescope for 333 how'd you do?\",\n",
       " 'But I think your statment there does that fine',\n",
       " \"I think they are arguing you didn't say it was in Q\",\n",
       " 'It is',\n",
       " 'how tf is |s| not 3p + 3',\n",
       " \"I'd regrade request that\",\n",
       " 'and i did use it',\n",
       " 'i did read it',\n",
       " 'wait nvm',\n",
       " \"You didn't write out s though\",\n",
       " 'i didnt read this',\n",
       " 'oh i realized, i didnt actually use their string',\n",
       " 'I lost apoint there cause 1+2+3 is *totally 5*',\n",
       " 'what did i do wrong here',\n",
       " 'Mainly my own stupidity on anything I missed',\n",
       " 'got a 137/150',\n",
       " 'Shit is finally graded',\n",
       " 'A minute amount of trolling',\n",
       " 'All lies',\n",
       " '\"end of the week\"',\n",
       " 'my live reaction to this information',\n",
       " 'What dee helll',\n",
       " 'Mfw when no 333 exam scores',\n",
       " 'Typo lol',\n",
       " 'before you edited',\n",
       " 'i was about to say',\n",
       " 'Valid the fact that the recordings dont exist is one of the only reasons I consistently show up',\n",
       " 'he is very lazy',\n",
       " 'matt never goes to class',\n",
       " 'me and connor sit in the back right of 1025 if you wind up coming',\n",
       " \"Yeah I'll just be a couple minutes late in accounting it'll buff\",\n",
       " 'i think',\n",
       " '1:30 to 2:45',\n",
       " 'How long does it run for',\n",
       " 'more like not care lol',\n",
       " \"Smart she'll prob not notice\",\n",
       " 'ive sat in on random lectures for other classes',\n",
       " 'unless you have something else to do',\n",
       " 'u can come to lecture at 1',\n",
       " 'I have no idea peobably todays lecture though \\nIm annoyed I overslept',\n",
       " 'a little bit',\n",
       " 'or for TSP i already know about it',\n",
       " 'only place i can find this is the internet',\n",
       " 'like for these problems',\n",
       " 'is there anywhere we talk about some NP problems in the notes?',\n",
       " 'I just reread this and yeah if it decides a problem it shouls always halt',\n",
       " 'Traveling Sales person proves it',\n",
       " '1 million gold doubloon prize',\n",
       " 'you should prove it',\n",
       " 'Yeah I know P != NP so I guess go with that',\n",
       " 'if it said \"for which we do not have\" it would make more sense',\n",
       " 'how does having a solution in P for some NP problems imply P != NP (i saw this was true in a previous HW, hence my answer)',\n",
       " 'the wording of this one is weird AF',\n",
       " 'This also is true because of your reasoning',\n",
       " 'i thought that meant we know if it halts or not also',\n",
       " 'You are correct an algorithm only exists if it decides the problem',\n",
       " 'this one too since it doesnt say the UTM WONT halt',\n",
       " 'since i though deciding a problem meant it halts',\n",
       " 'this one seems trolled',\n",
       " 'not yet',\n",
       " 'You go to the lecture for today?',\n",
       " 'Dammnit my stupid ass overslept',\n",
       " 'theres quite a couple i cant find in the notes',\n",
       " 'i might get clapped on this hw',\n",
       " \"Now I wish I didn't so\",\n",
       " 'Ie why I erased those transitions since I was panicked',\n",
       " 'well it looks like it could be right although some of those double transitions seem a bit wacky',\n",
       " 'Was just the placeholder I used to track the Ps',\n",
       " 'do you pop an A?',\n",
       " 'From what I could tell this is prob the correct answer\\nBecause I panicked I erased the 2nd one that allow n=0',\n",
       " 'Then it was a little 4 state diagram',\n",
       " 'So D P^n D^n A',\n",
       " 'SAME THING BUT LETTERS WERE DPDA',\n",
       " 'mine was N C^N S^N U',\n",
       " 'what was your dpda',\n",
       " 'I can show what I think the intended solution was\\nIt required some creative stack use',\n",
       " 'took me a couple minutes to realize i probably screwed up',\n",
       " 'So that feels bad',\n",
       " 'After I turned it in I insta realized that the case I used to prove my original solution was nondeterministic I was wrong',\n",
       " 'Yeah whats annoying is I got it right\\nOverthought it\\nRaised my hand asked if that was a mistake\\nThey were dodgy and weird so I erased it and just solved it for > 0',\n",
       " 'Did yours have >= 0 or just > 0',\n",
       " 'That dpda fucked me up',\n",
       " 'on the dpda i used an epsilon arrow',\n",
       " 'i think theres only 1 spot i might have messed up',\n",
       " 'well enough',\n",
       " \"How'd the test go btw\",\n",
       " \"I'm coming out now also\",\n",
       " 'Lmao connor',\n",
       " 'What thier name lol dont wanna just walk up like a creep',\n",
       " 'But look for this guy',\n",
       " \"I'm in the bathroom\",\n",
       " 'Left I believe',\n",
       " 'Looking for you\\nRight or left facing atrium',\n",
       " 'But in the mulch',\n",
       " 'Near the ranting preachers',\n",
       " \"I'm at a tree bench\",\n",
       " 'Heading to Hill',\n",
       " \"I'm gonna go look for spots in Hill\",\n",
       " 'Talley is pretty packed so perhaps we should go to hill',\n",
       " \"Cool let me finish this quiz and I'll head over\",\n",
       " 'if there arent then we can always go to the library',\n",
       " 'ill be heading to talley soon to see if there are any seats',\n",
       " 'Sounds good',\n",
       " 'Talley after 1 then?',\n",
       " \"Let's do Talley then\",\n",
       " 'Either Talley or Hill is best for me\\nHunt is a little out of the way for me tomorrow',\n",
       " 'Talley works, so does either library',\n",
       " 'Uh\\nWhats close to you\\nI live at Wood so Talley is where I usually go, but Im pretty flexible',\n",
       " 'Where do you want to meet tomorrow',\n",
       " \"Yeah mine's at 10:15 wed\",\n",
       " 'Ah right the other session is an afternoon not a day over',\n",
       " '1 pm',\n",
       " 'What day is your exam on?\\nThurs?',\n",
       " 'Sounds good to me',\n",
       " 'how about some time on tuesday after 1?',\n",
       " \"I'm free all day Tues\\nMon any time after 4:30, but I do have OS stuff to work on\",\n",
       " 'i might have a friend who is interested also',\n",
       " 'sure, when?',\n",
       " 'Btw, you want to meet up and study for the midterm at some point this week?',\n",
       " 'Fair, my calc 3 was like that',\n",
       " 'though that said I always come prepared with an attempt at a solution',\n",
       " 'half the time it feels like im basically getting the prof to do my hw for me lol',\n",
       " 'Like I figured it out but I could have saved so much time',\n",
       " 'It would have been helpful when I was first struggling with induction',\n",
       " 'ive only ever gone for MA classes',\n",
       " 'Never went to office hours or anything',\n",
       " \"Same I wish I wasn't a moron when I took 226 lol\",\n",
       " 'very helpful',\n",
       " 'like MA 225 and 405 are /were very proof intensive and i went weekly to the office hours',\n",
       " 'i like office hours especially for classes where I have to do logic proofs',\n",
       " \"I'm just gonna go to office hours and ask though idk\",\n",
       " 'Yeah but that part was marked correct on case 2',\n",
       " 'one thing i can see is that n is a symbol thats already used earlier to define the language so it could be a bit confusing',\n",
       " 'Which logically yeah I should have put the main variable on the y',\n",
       " \"Every thing was marked as right other than the z's here\",\n",
       " 'what was your proof?',\n",
       " \"Apparently my z's were wrong\",\n",
       " 'i used a fair deal of symbols lol',\n",
       " 'this was my proof',\n",
       " 'number 3 hw 8?',\n",
       " 'at least the proof HWs',\n",
       " 'Because I looked at the solution and it seemed like the same thing',\n",
       " 'its really similar to my math hws',\n",
       " 'Gonna go to office hours and ask',\n",
       " 'I actually think thats one area where I feel good',\n",
       " \"Apparently I didn't do to hot on the multi case question in the hw?\",\n",
       " 'This one',\n",
       " \"At least we won't have to create a Turing machine on it\",\n",
       " 'or for regular languages?',\n",
       " 'for CFGs?',\n",
       " \"Only thing I'm a little iffy on is pumping lemma stuff\",\n",
       " \"Ah that's rough\",\n",
       " 'so i did dumb things like for the {1,2} accepting DFA i made one that accepted only {12}',\n",
       " 'when i got it back i knew exactly how to do the problems, its just that I didnt read them fully before commiting to an answer',\n",
       " 'made a poor score for no good reason',\n",
       " 'That happen last time?',\n",
       " 'i wasnt even rushing because i was low on time',\n",
       " 'hopefully this test i dont fuck up and forget to read the last half of all the questions',\n",
       " 'That fixed it\\nBroke my drawing but that was no sweat to fix with a SS',\n",
       " \"I'm gonna try that\",\n",
       " 'No I used docs',\n",
       " 'did u use MS office',\n",
       " 'Mine shits itself entirely',\n",
       " 'i can copy from my pdf with only like 1 error',\n",
       " 'Since my code is a little longer',\n",
       " 'The pdf cause the text to be janky',\n",
       " 'as in copy some text from a pdf?',\n",
       " 'Hey you got any tips on how to get your turing machine code to copy and paste properly from a pdf?',\n",
       " 'this took like 2-4 hours to completely devolve into another piazza rant lmao',\n",
       " 'and then this happened',\n",
       " 'this post was made (and now deleted)',\n",
       " 'but not before it was saved',\n",
       " 'and it just got deleted',\n",
       " 'he went off on another rant',\n",
       " 'oh my fucking god',\n",
       " 'Yeah he\\'ll have to go to the \"hearing\" or whatever they wanna call it',\n",
       " 'piazza ban also sounds reasonable',\n",
       " 'maybe a required meeting is my guess',\n",
       " 'Prob a written warning and maybe banned from posting on piazza',\n",
       " 'Some of the sanctions in section 11',\n",
       " \"Didn't really talk to him outside of working on that 316 project\",\n",
       " \"Because if so, he's my neighbor\",\n",
       " 'Also does he live in Avent ferry',\n",
       " \"Wonder what's gonna happen to him, if anything\",\n",
       " 'The funny part is he outed himself in that post regardless of if it was anonymous to instructors',\n",
       " 'That or a TA',\n",
       " \"At least, that's my head canon\",\n",
       " \"I'm guessing someone mentioned it in passing on office hours and she said wtf? And then learned about it\",\n",
       " 'Well she did say she was just now brought up to speed about it',\n",
       " 'Pretty tame compared to the original ngl\\nKinda surprised she responded this late?',\n",
       " 'In piazza?',\n",
       " 'Oh lord',\n",
       " 'Looks like Dr Jennings found out about the piazza rant',\n",
       " 'ðŸ’£ just dropped',\n",
       " 'either way its the same answer, so i feel good about it',\n",
       " 'Its asking if it looping forever means it accepts',\n",
       " \"guessing its a typo since part f says the same thing but f is asking if it doesn't accept or halt and just loops forever\",\n",
       " 'these are two contradictory statements\\nis it giving me the answer?',\n",
       " 'also wtf does part e say',\n",
       " 'Lmao thats neat',\n",
       " 'either way im just using it to check my handwork',\n",
       " 'would be funny if its wrong and it trolls me',\n",
       " 'pretty sure i made it right',\n",
       " '`//LOAD AN EXAMPLE TO TRY\\n//then load an input and click play\\n\\n//Syntax:\\n\\n//-------CONFIGURATION\\nname: mystery.exe\\ninit: 1\\naccept: 3\\n\\n//-------DELTA FUNCTION:\\n//[current_state],[read_symbol]\\n//[new_state],[write_symbol],[>|<|-]\\n\\n1,a\\n1,a,>\\n\\n1,b\\n1,b,>\\n\\n1,_\\n2,_,<\\n\\n2,a\\n3,a,<\\n\\n2,b\\n4,a,<\\n\\n4,b\\n4,a,<\\n\\n4,a\\n5,a,<\\n\\n5,a\\n5,a,<\\n\\n5,b\\n5,a,<\\n\\n5,_\\n5,_,>\\n\\n\\n// < = left\\n// > = right\\n// - = hold\\n// use underscore for blank cells\\n\\n//States and symbols are case-sensitive\\n\\n//Load your code and click COMPILE.\\n//or load an example (top-right).\\n`',\n",
       " 'made a program for hw 8 problem 2',\n",
       " 'this turing machine simulator website seems pretty decent',\n",
       " 'Since yknow that never came up with nfas',\n",
       " 'Yeah the logic that itd run forever wasnt tracking for me',\n",
       " 'i looked in an older hw and it looks like google lied to me',\n",
       " 'i suppose ill find out whats what in about 4ish hours',\n",
       " \"Same I was heading there now\\nMy gut says that if epsilon was letting it loop it'd still either pass or fail since you either can get to a success state or not no matter how many times you loop\",\n",
       " 'i can just ask dr jennings for the answer',\n",
       " 'actually i just realized i have 333 today lmao',\n",
       " \"I can't find anywhere in the notes where this is either supported or contradicted\",\n",
       " 'But I guess epsilon arrows exist',\n",
       " 'Hmm I feel like it would run out of input eventually',\n",
       " 'google said this is false',\n",
       " 'Wym by infinite loops?',\n",
       " \"for this newest HW, I'm pretty sure that PDAs can have infinite loops (because i googled it lmao) but I can't find anywhere in the notes where it says this, or contradicts this\",\n",
       " 'In that case I am finished\\nThank you for the reminder earlier this week I wouldnt have seen it at all had you not mentioned it',\n",
       " 'at least, i think so',\n",
       " 'oh yea they can',\n",
       " 'Like two arrows that read x and go to different states',\n",
       " 'if an nfa can have it, a pda probably can too',\n",
       " 'like what',\n",
       " 'Hey quick question PDAs can have duplicate arrows like an NFA right?',\n",
       " 'Yeah I might be able to finish it tonight if I can do this Accounting quiz quickly',\n",
       " \"This week's homework wasn't too bad, especially once I figured out how to think about pdas, so it shouldnt take too much effort\",\n",
       " 'Just wanted to make sure there was no waiver like in 316 or anything',\n",
       " 'Rip lol',\n",
       " 'Yeah thats why its the assignment that has to get pushed back lmao',\n",
       " 'At least she says she drops the penalty for 2 of them',\n",
       " \"Have other stuff due so I guess I'll just have to eat a late\",\n",
       " 'Oh thanks\\nI completely lost track of time this week and forgot about the one due tonight',\n",
       " '\"Gradescope keeps track of late assignments, though it does not automatically deduct any late points because it is not sufficiently flexible to allow us to configure some number of \"free\" late assignments.\\n\\nAt the end of the term, I query gradescope for the number of late assignments, subtract the two free late ones, and then deduct the penalty for any additional late ones.\"',\n",
       " 'I found this post which should answer it pretty well',\n",
       " 'Hey do you know if there is some sort of waiver we need to turn in when submitting a hw late',\n",
       " 'now time to ask Prof Jennings to give me all the answers',\n",
       " 'took around an hour to 2 hours',\n",
       " 'i have finished it',\n",
       " 'Makes sense',\n",
       " 'and 4 is making another PDA',\n",
       " '3 is reading a PDA',\n",
       " '2 is making a PDA',\n",
       " 'i did it one way which im not sure she will accept',\n",
       " 'and specifically, showing my thing is in the language',\n",
       " 'only bit im not sure on is 1b',\n",
       " '1 is pumping lemma',\n",
       " 'which i think i do a little bit',\n",
       " 'if you understand PDAs',\n",
       " 'Fair enough\\nIt pretty straight forward?',\n",
       " 'its on the piazza now regardless',\n",
       " 'i know i started it at about 11 today',\n",
       " 'i think either last night or this morning',\n",
       " 'When she upload this? I didnt realize she had posted it',\n",
       " 'unless i did it wrong',\n",
       " 'at least num 3 seems like it was really easy',\n",
       " 'So fair',\n",
       " \"lets go, i'm already lost on how to make a PDA for number 2 in HW6\\nor perhaps not quite lost, but more like banging around in the dark of my own home after someone rearranged all the furniture\",\n",
       " 'but then he regraded everyone immediately',\n",
       " 'he did make a mistake and take pts off everyone cuz he miscalculated the mantissa of a float',\n",
       " 'with him anyways',\n",
       " 'so im not too upset',\n",
       " 'instead of just using a null terminator to find the length of a string',\n",
       " 'like using the sizeof trick where it wouldnt work',\n",
       " 'admittedly, I understand where I lost all my points',\n",
       " 'Yeah I got 90+ on both midterms then got a 70 on the final cause Balik used Sturgills final',\n",
       " 'Yeah where it is no applications and all his shit quizes lol',\n",
       " 'sturgill did a little tomfoolery, a little pranking if you will, on the test',\n",
       " 'made a 78/100 on my 230 test though',\n",
       " 'either way i passed, so im happy',\n",
       " 'maybe i got a 78/100 and its just not showing me the gradescope',\n",
       " 'Gotcha\\nDamn idk guess I just have skill issue lol',\n",
       " 'as in, they wouldnt be out of place on a workshop',\n",
       " 'they were basically all workshop tier questions',\n",
       " 'but around 20-30',\n",
       " 'i cant check',\n",
       " 'i think it was around 20',\n",
       " 'How many questions was it',\n",
       " 'which trolled massively one problem',\n",
       " 'also though it came after n',\n",
       " 'since i forgot how the alphabet worked, and thought that l came after m in the english alphabet',\n",
       " 'but im not certain',\n",
       " 'i think 2 + a final',\n",
       " 'I mean total lol',\n",
       " 'so far',\n",
       " 'How many tests you have?',\n",
       " 'idk how i made 78.67 unless my only mistake was on a quicksort thing',\n",
       " 'all this',\n",
       " 'What did it cover?',\n",
       " 'Damn thats imprrssive',\n",
       " 'on the non-pseudocode',\n",
       " 'but i made 78.67 out of 80',\n",
       " '20 pts are pseudocode which still havent been graded',\n",
       " 'You got the grade back for it?',\n",
       " 'i think thats more accurate',\n",
       " 'or a practice test',\n",
       " 'test 1 went pretty well, since to prepare i just taped workshops 1-4 together in a png file and used it as a study guide',\n",
       " 'The tests are just as in-depth as the workshops',\n",
       " 'Also compiling all the runtimes is helpful',\n",
       " 'yea they are',\n",
       " '~~Assuming tests are still open note online lol~~',\n",
       " 'For the test make a cheat sheet so you have a reference sheet for tree processes it will save so much time',\n",
       " 'doesnt let me go too far ahead',\n",
       " 'i can access the lecture slides for 2-4 trees but thats it',\n",
       " 'Splay is stupid easy',\n",
       " '2-4 and red-blacks are slighly painful',\n",
       " 'havent gotten to that one yet',\n",
       " 'Red-blacks are the rough ones',\n",
       " 'zig and zag trees',\n",
       " 'i cannot take that word seriously',\n",
       " 'except maybe remembering exactly how to zig or zag or zig zag trees',\n",
       " \"Ya'll hit trees yet?\",\n",
       " 'then again, nothing so far has been really complicated',\n",
       " 'hopefully my MA 351 knowledge will carry me through graphs',\n",
       " 'Then does Dijkstras, Prim-Jarniks, and Kruskals',\n",
       " 'Then does graphs',\n",
       " 'He covers it before graphs',\n",
       " 'oh ok',\n",
       " 'Yeah cause King covers that later in the semester',\n",
       " 'well neither do i',\n",
       " 'Yeah they passed with like a 98 the problem is now they are in an Algorithms course and had no idea what a heap was',\n",
       " 'they didnt comment their algorithm',\n",
       " 'oh my fucking god',\n",
       " 'well if they passed, then good for them',\n",
       " 'And then they had the credit to skip the 1st two coding classes',\n",
       " 'Like literally their Data Structures instructor is being imvestigated for not meeting course requirments last semester',\n",
       " 'Jokes on you they were never taught it',\n",
       " \"its how I got a filechooser in one of my projects, by copying sarah heckman's code for one\",\n",
       " 'just steal the UI code from 216/whatever other class at UNCC gives you ok looking UIs',\n",
       " 'My friend over at UNCC had to make this whole complex ass gui in swing and it looked nightmarish',\n",
       " 'its definitely haunted',\n",
       " 'it will go to something elses center',\n",
       " \"but then it wont go to the component's center\",\n",
       " 'like i can tell something to use border layout and then set it to the center',\n",
       " 'yea its a bit haunted',\n",
       " 'Another day of thanking god I dont have to use Swing',\n",
       " 'if it can be command line thats not too bad either',\n",
       " 'oh ok',\n",
       " 'Plot twist is you dont get one\\nWe had to make whatever UI we wanted but it could be a command-line interface',\n",
       " 'You are going to export you data structures project as a jar\\nThen add a jar they give too that will give controlled access to it',\n",
       " 'even though i can make a shitty one if pressed, I really dont want to',\n",
       " 'we dont have to make the UI, i hope',\n",
       " 'and the other half is normal',\n",
       " 'You wont actually have to make everything though',\n",
       " 'its like half of it got stretched a bit',\n",
       " 'But yeah that is exactly what they are fishing for',\n",
       " 'because not all of it is like this',\n",
       " 'its weird',\n",
       " 'ðŸ˜‹ crispy text',\n",
       " 'Si mobile moment',\n",
       " 'going? lol',\n",
       " 'They are doing to the oblivion',\n",
       " 'No yours is right',\n",
       " 'but I might be wrong',\n",
       " 'i thought we had to include literally everything',\n",
       " 'meanwhile the other person has a stretched picture from 1998',\n",
       " 'this is what mine looks like',\n",
       " 'I gave one of the ones I had to review a 13 just cause it was so horendous',\n",
       " 'Its out of like 30 points right?',\n",
       " 'Oh god yeah',\n",
       " 'this UML got abused',\n",
       " 'well actually just 1',\n",
       " 'i gotta give peer feedback to project 1 in 316 and both of the people have some ðŸ¤® UML diagrams',\n",
       " 'She is def not a hardass like King or Sturgill',\n",
       " \"Also she may curve it but we'll see\",\n",
       " 'or problem attempt grade',\n",
       " 'wish more classes had participation grade factored into the test lol',\n",
       " 'thats good',\n",
       " 'Though I talked to Jiao and she told me explicitly they are going to be giving partial credit as well as \"attempt\" credit',\n",
       " \"The problem was loke half the test was on a topic we'd had no assignments on\",\n",
       " 'Good to know everyone felt shitty about it lol',\n",
       " 'Pretty worried about how I did on that test',\n",
       " 'my friend in OS said he got trolled on the test',\n",
       " 'The same cannot be said about OS though',\n",
       " 'Yeah Im def in the same boat here',\n",
       " \"i think i'll still get an A\",\n",
       " 'Yeah pretty sure it was cause of how thungs dustriputed',\n",
       " 'since i am almost certain thats the only mistake I made on the push down automaton',\n",
       " 'its probably just like 1 or 2 pts',\n",
       " 'Ah thats rough',\n",
       " 'since i immediately turned it in and realized one of the things i said wouldnt accept would, in fact, accept',\n",
       " 'theres no way i made a 100, and it would take a natural disaster to make less than an 80',\n",
       " 'Though tbh I know I aced this one',\n",
       " 'wonder when we will get our test scores back',\n",
       " 'My stupid ass put the error state in the center',\n",
       " 'final state?',\n",
       " \"Wait nvm I'm dumbass\",\n",
       " 'what in tarnation',\n",
       " 'Starting state has an arrow to it',\n",
       " 'start shouldnt go to error',\n",
       " 'Yeah my issue is the start state isnt giving me one that would push to the error state is the thing',\n",
       " 'my answer works with their picture',\n",
       " 'as long as u get the same number of states they have in their fill in the blank pic u should be good',\n",
       " 'I think it means to pick the statment that defines it',\n",
       " 'from this test',\n",
       " 'i just realized i got trolled on 3d',\n",
       " 'They can',\n",
       " 'Hw 5 Q2 mixing me up rn',\n",
       " \"Yeah that's kinda scuffed\",\n",
       " 'hope the actual test is more clear',\n",
       " \"i guess it must have been meaning for me to select the only answer that didn't also apply to NFAs\",\n",
       " 'troll question: i thought,  and am still pretty sure DFAs could have multiple final states']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add each message to a corpus. Each message is separated by a comma.\n",
    "\n",
    "corpus = []\n",
    "originalMessageIndexMap = {}\n",
    "for i in range(len(data)):\n",
    "    # Skip over NaN values\n",
    "    if pd.isnull(data.iloc[i, 15]):\n",
    "        continue\n",
    "    # Skip over messages with only one word\n",
    "    if len(data.iloc[i, 15].split()) == 1:\n",
    "        continue\n",
    "    corpus.append(data.iloc[i, 15])\n",
    "    originalMessageIndexMap[len(corpus) - 1] = i\n",
    "    \n",
    "display(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<449x1059 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3611 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use TF-IDF to find the most important words in the corpus\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar messages using 7 neighbors:\n",
      "its really similar to my math hws\n",
      "312/320 here\n",
      "I feel like I should be fine but claculating the HW grade is such a pain I dont want to bother yknow\n",
      "What thier name lol dont wanna just walk up like a creep\n",
      "Maybe it just means taking both is an excess of units but who knows\n",
      "i need the one for this\n",
      "like when i made a dfa that accepted a single string like \"blah\" when they wanted it to only accept \"b\", \"l\", \"a\" or \"h\" (something like that, i forgot exactly\n",
      "I have no idea peobably todays lecture though \n",
      "Im annoyed I overslept\n",
      "author.username                          diruslupito\n",
      "content            its really similar to my math hws\n",
      "Name: 232, dtype: object\n",
      "author.username                                        gamemaster618\n",
      "content            312/320 here\\nI feel like I should be fine but...\n",
      "Name: 56, dtype: object\n",
      "author.username                                        gamemaster618\n",
      "content            What thier name lol dont wanna just walk up li...\n",
      "Name: 169, dtype: object\n",
      "author.username                                        gamemaster618\n",
      "content            Maybe it just means taking both is an excess o...\n",
      "Name: 13, dtype: object\n",
      "author.username                diruslupito\n",
      "content            i need the one for this\n",
      "Name: 40, dtype: object\n",
      "author.username                                          diruslupito\n",
      "content            like when i made a dfa that accepted a single ...\n",
      "Name: 44, dtype: object\n",
      "author.username                                        gamemaster618\n",
      "content            I have no idea peobably todays lecture though ...\n",
      "Name: 109, dtype: object\n",
      "Distances: [1.02621842 1.41421356 1.41421356 1.41421356 1.41421356 1.41421356\n",
      " 1.41421356]\n"
     ]
    }
   ],
   "source": [
    "# Use a K-NN model to find the most similar messages to the most recent message, \n",
    "# using 7 neighbors\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "sevenNbrs = NearestNeighbors(n_neighbors=7).fit(tfidf_matrix)\n",
    "\n",
    "# Find the most similar messages to the given message\n",
    "\n",
    "mostRecentMessageTFIDF = vectorizer.transform(['math'])\n",
    "distances, indices = sevenNbrs.kneighbors(mostRecentMessageTFIDF)\n",
    "print('Most similar messages using 7 neighbors:')\n",
    "for i in range(7):\n",
    "    print(corpus[indices[0][i]])\n",
    "for i in range(7):\n",
    "    print(data.iloc[originalMessageIndexMap[indices[0][i]], [4,15]])\n",
    "print(f'Distances: {distances[0]}')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
